{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 4769020,
     "sourceType": "datasetVersion",
     "datasetId": 2760272
    },
    {
     "sourceId": 565176,
     "sourceType": "modelInstanceVersion",
     "isSourceIdPinned": true,
     "modelInstanceId": 426785,
     "modelId": 443823
    },
    {
     "sourceId": 565180,
     "sourceType": "modelInstanceVersion",
     "isSourceIdPinned": true,
     "modelInstanceId": 426787,
     "modelId": 443825
    }
   ],
   "dockerImageVersionId": 31090,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": "import os\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.preprocessing import image\nimport tensorflow as tf",
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-09-07T16:52:06.480083Z",
     "iopub.status.idle": "2025-09-07T16:52:06.480404Z",
     "shell.execute_reply.started": "2025-09-07T16:52:06.480228Z",
     "shell.execute_reply": "2025-09-07T16:52:06.480246Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "data_dir = '/kaggle/input/real-time-anomaly-detection-in-cctv-surveillance/'\nvideo_dir = os.path.join(data_dir, 'data')\ntrain_csv = os.path.join(video_dir, 'train.csv')\ntest_csv = os.path.join(video_dir, 'test.csv')\nprint(\"Dataset root contents:\", os.listdir(data_dir))\nprint(\"Video dir contents:\", os.listdir(video_dir))\nprint(f\"Train CSV path: {train_csv}, Exists: {os.path.exists(train_csv)}\")\nprint(f\"Test CSV path: {test_csv}, Exists: {os.path.exists(test_csv)}\")\nthreat_classes = ['abuse', 'arrest', 'arson', 'assault', 'burglary', 'explosion', \n                  'fighting', 'roadaccidents', 'robbery', 'shooting', 'shoplifting', \n                  'stealing', 'vandalism']\nnormal_class = ['normal']\ndef extract_frames(video_path, num_frames=5):\n    cap = cv2.VideoCapture(video_path)\n    if not cap.isOpened():\n        print(f\"Failed to open video: {video_path}\")\n        return []\n    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    step = max(1, total_frames // num_frames)\n    frames = []\n    for i in range(0, total_frames, step):\n        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n        ret, frame = cap.read()\n        if ret:\n            frames.append(cv2.resize(frame, (224, 224)))\n        if len(frames) >= num_frames: break\n    cap.release()\n    return frames\n\nmodel = ResNet50(weights='imagenet', include_top=False, pooling='avg')\ndef extract_cnn_features(frames):\n    if not frames:\n        return None\n    features = []\n    for frame in frames:\n        frame_array = image.img_to_array(frame)\n        frame_array = np.expand_dims(frame_array, axis=0)\n        frame_array = tf.keras.applications.resnet50.preprocess_input(frame_array)\n        feat = model.predict(frame_array, verbose=0)\n        features.append(feat.flatten())\n    return np.mean(features, axis=0)\n\n# Load training data from train.csv\ntrain_df = pd.read_csv(train_csv)\nprint(\"Train CSV columns:\", train_df.columns)\nprint(\"Train CSV head:\\n\", train_df.head())\nX_train, y_train = [], []\nfor index, row in train_df.iterrows():\n    # Adjust column names based on actual CSV structure (e.g., 'video_path', 'label')\n    relative_path = row['video_name'].replace('\\n', '').replace('\\\\', '/')\n    video_path = os.path.join(data_dir, relative_path)\n    label = 1 if row['label'] in threat_classes else (0 if row['label'] in normal_class else -1)\n    if label == -1: continue\n    # print(f\"Processing: {video_path}\")\n    frames = extract_frames(video_path)\n    if frames:\n        features = extract_cnn_features(frames)\n        if features is not None:\n            X_train.append(features)\n            y_train.append(label)\n\n# Convert training data to numpy arrays\nX_train = np.array(X_train)\ny_train = np.array(y_train)\nprint(f\"Train data shape: {X_train.shape}, Train labels shape: {y_train.shape}\")\n\nif X_train.shape[0] == 0:\n    raise ValueError(\"No training data loaded. Check train.csv and video files.\")",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-09-07T10:51:11.847139Z",
     "iopub.execute_input": "2025-09-07T10:51:11.847534Z",
     "iopub.status.idle": "2025-09-07T11:06:31.450265Z",
     "shell.execute_reply.started": "2025-09-07T10:51:11.847515Z",
     "shell.execute_reply": "2025-09-07T11:06:31.449485Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Dataset root contents: ['data']\nVideo dir contents: ['roadaccidents', 'assault', 'vandalism', 'arrest', 'shooting', 'arson', 'explosion', 'normal', 'shoplifting', 'robbery', 'stealing', 'burglary', 'train.csv', 'test.csv', 'abuse', 'fighting']\nTrain CSV path: /kaggle/input/real-time-anomaly-detection-in-cctv-surveillance/data/train.csv, Exists: True\nTest CSV path: /kaggle/input/real-time-anomaly-detection-in-cctv-surveillance/data/test.csv, Exists: True\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "I0000 00:00:1757242272.636413      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1757242272.637106      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001B[1m94765736/94765736\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 0us/step\nTrain CSV columns: Index(['Unnamed: 0', 'label', 'video_name'], dtype='object')\nTrain CSV head:\n    Unnamed: 0          label                                    video_name\n0        1229         normal        data\\normal\\Normal_Videos_196_x264.mp4\n1         551         normal         data\\normal\\Normal_Videos179_x264.mp4\n2         715         normal         data\\normal\\Normal_Videos361_x264.mp4\n3        1366  roadaccidents  data\\roadaccidents\\RoadAccidents017_x264.mp4\n4         501         normal         data\\normal\\Normal_Videos125_x264.mp4\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1757242278.616307      84 service.cc:148] XLA service 0x7a4b48004100 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1757242278.616952      84 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1757242278.616993      84 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1757242279.224768      84 cuda_dnn.cc:529] Loaded cuDNN version 90300\nI0000 00:00:1757242281.663131      84 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Train data shape: (1520, 2048), Train labels shape: (1520,)\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": "model.save('resnet50_finetuned.h5')\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-09-07T11:29:08.579739Z",
     "iopub.execute_input": "2025-09-07T11:29:08.580485Z",
     "iopub.status.idle": "2025-09-07T11:29:09.019551Z",
     "shell.execute_reply.started": "2025-09-07T11:29:08.580461Z",
     "shell.execute_reply": "2025-09-07T11:29:09.019004Z"
    }
   },
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": "svm_model = SVC(kernel='rbf', C=1.0, gamma='scale')\nsvm_model.fit(X_train, y_train)\n\n# Load test data from test.csv\ntest_df = pd.read_csv(test_csv)\nX_test, y_test = [], []\nfor index, row in test_df.iterrows():\n    relative_path = row['video_name'].replace('\\n', '').replace('\\\\', '/')\n    video_path = os.path.join(data_dir, relative_path)\n    label = 1 if row['label'] in threat_classes else (0 if row['label'] in normal_class else -1)\n    if label == -1: continue\n    frames = extract_frames(video_path)\n    if frames:\n        features = extract_cnn_features(frames)\n        if features is not None:\n            X_test.append(features)\n            y_test.append(label)\n\n# Convert test data to numpy arrays\nX_test = np.array(X_test)\ny_test = np.array(y_test)\nprint(f\"Test data shape: {X_test.shape}, Test labels shape: {y_test.shape}\")",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-09-07T11:06:31.452002Z",
     "iopub.execute_input": "2025-09-07T11:06:31.452215Z",
     "iopub.status.idle": "2025-09-07T11:10:27.365344Z",
     "shell.execute_reply.started": "2025-09-07T11:06:31.452198Z",
     "shell.execute_reply": "2025-09-07T11:10:27.364512Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Test data shape: (380, 2048), Test labels shape: (380,)\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": "# Simulate real-time analysis with a test video\ntest_video = os.path.join(video_dir,'Abuse001_x264.mp4')  # Adjust based on actual file\ncap = cv2.VideoCapture(test_video)\nframe_buffer = []\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret: break\n    frame_resized = cv2.resize(frame, (224, 224))\n    frame_buffer.append(frame_resized)\n    if len(frame_buffer) > 5:\n        frame_buffer.pop(0)\n    if len(frame_buffer) == 5:\n        features = extract_cnn_features(frame_buffer)\n        if features is not None:\n            prediction = svm_model.predict([features])[0]\n            label = \"Threat\" if prediction == 1 else \"Normal\"\n            print(f\"Prediction: {label}\")\ncap.release()",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-09-07T11:10:27.366150Z",
     "iopub.execute_input": "2025-09-07T11:10:27.366419Z",
     "iopub.status.idle": "2025-09-07T11:10:27.375278Z",
     "shell.execute_reply.started": "2025-09-07T11:10:27.366401Z",
     "shell.execute_reply": "2025-09-07T11:10:27.374739Z"
    }
   },
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": "# Model Evaluation\ny_pred = svm_model.predict(X_test)\nprint(\"Accuracy of the model in percentage:\", accuracy_score(y_test, y_pred)*100)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-09-07T11:10:27.375904Z",
     "iopub.execute_input": "2025-09-07T11:10:27.376118Z",
     "iopub.status.idle": "2025-09-07T11:10:27.992864Z",
     "shell.execute_reply.started": "2025-09-07T11:10:27.376102Z",
     "shell.execute_reply": "2025-09-07T11:10:27.992229Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Accuracy of the model in percentage: 88.68421052631578\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": "test_video_1 = os.path.join(video_dir, 'abuse/Abuse001_x264.mp4')\nframes = extract_frames(test_video_1) \nfeatures = extract_cnn_features(frames)\nprediction = svm_model.predict([features])[0]\nlabel = \"Threat\" if prediction == 1 else \"Normal\"\nprint(f\"Prediction: {label}\")",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-09-07T11:10:27.993595Z",
     "iopub.execute_input": "2025-09-07T11:10:27.993822Z",
     "iopub.status.idle": "2025-09-07T11:10:28.555516Z",
     "shell.execute_reply.started": "2025-09-07T11:10:27.993796Z",
     "shell.execute_reply": "2025-09-07T11:10:28.554905Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Prediction: Threat\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "import joblib\n",
    "joblib.dump(svm_model, '/kaggle/working/svm_model.pkl')\n",
    "print(\"Model saved to /kaggle/working/svm_model.pkl\")"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-09-07T11:10:28.556219Z",
     "iopub.execute_input": "2025-09-07T11:10:28.556433Z",
     "iopub.status.idle": "2025-09-07T11:10:28.577264Z",
     "shell.execute_reply.started": "2025-09-07T11:10:28.556410Z",
     "shell.execute_reply": "2025-09-07T11:10:28.576483Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Model saved to /kaggle/working/svm_model.pkl\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import joblib\n",
    "video_path = \"/kaggle/input/real-time-anomaly-detection-in-cctv-surveillance/data/normal/Normal_Videos001_x264.mp4\"\n",
    "model = ResNet50(weights='imagenet', include_top=False, pooling='avg')\n",
    "\n",
    "svm_model = joblib.load('/kaggle/input/svmbasedmodel/pytorch/default/1/svm_model.pkl')\n",
    "\n",
    "# Function to extract frames\n",
    "def extract_frames(video_path, num_frames=5):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Failed to open video: {video_path}\")\n",
    "        return []\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    step = max(1, total_frames // num_frames)\n",
    "    frames = []\n",
    "    for i in range(0, total_frames, step):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frames.append(cv2.resize(frame, (224, 224)))\n",
    "        if len(frames) >= num_frames: break\n",
    "    cap.release()\n",
    "    return frames\n",
    "def extract_cnn_features(frames):\n",
    "    features = []\n",
    "    for frame in frames:\n",
    "        frame_array = image.img_to_array(frame)\n",
    "        frame_array = np.expand_dims(frame_array, axis=0)\n",
    "        frame_array = tf.keras.applications.resnet50.preprocess_input(frame_array)\n",
    "        feat = model.predict(frame_array, verbose=0)\n",
    "        features.append(feat.flatten())\n",
    "    return np.mean(features, axis=0)\n",
    "\n",
    "total_start = time.time()\n",
    "t0 = time.time()\n",
    "frames = extract_frames(video_path)\n",
    "t1 = time.time()\n",
    "print(f\"Frame extraction took: {t1 - t0:.2f} seconds, {len(frames)} frames extracted\")\n",
    "t2 = time.time()\n",
    "features = extract_cnn_features(frames)\n",
    "t3 = time.time()\n",
    "print(f\"ResNet feature extraction took: {t3 - t2:.2f} seconds\")\n",
    "t4 = time.time()\n",
    "features = features.reshape(1, -1)  # reshape for SVM\n",
    "y_pred = svm_model.predict(features)\n",
    "t5 = time.time()\n",
    "print(f\"SVM prediction took: {t5 - t4:.4f} seconds\")\n",
    "print(\"Predicted label:\", y_pred[0])\n",
    "\n",
    "total_end = time.time()\n",
    "print(f\"Total processing time: {total_end - total_start:.2f} seconds\")\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-09-07T11:39:36.404005Z",
     "iopub.execute_input": "2025-09-07T11:39:36.404308Z",
     "iopub.status.idle": "2025-09-07T11:39:41.336956Z",
     "shell.execute_reply.started": "2025-09-07T11:39:36.404284Z",
     "shell.execute_reply": "2025-09-07T11:39:41.336172Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Frame extraction took: 0.19 seconds, 5 frames extracted\nResNet feature extraction took: 3.59 seconds\nSVM prediction took: 0.0024 seconds\nPredicted label: 0\nTotal processing time: 3.78 seconds\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "\n",
    "video_path = \"/kaggle/input/real-time-anomaly-detection-in-cctv-surveillance/data/normal/Normal_Videos001_x264.mp4\"\n",
    "model = ResNet50(weights='imagenet', include_top=False, pooling='avg')\n",
    "svm_model = joblib.load('/kaggle/input/svmbasedmodel/pytorch/default/1/svm_model.pkl')\n",
    "def extract_frames(video_path, num_frames=100):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Failed to open video: {video_path}\")\n",
    "        return []\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    step = max(1, total_frames // num_frames)\n",
    "    frames = []\n",
    "    for i in range(0, total_frames, step):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frames.append(cv2.resize(frame, (224, 224)))\n",
    "        if len(frames) >= num_frames: break\n",
    "    cap.release()\n",
    "    return frames\n",
    "\n",
    "# Function to extract CNN features\n",
    "def extract_cnn_features(frames):\n",
    "    features = []\n",
    "    for frame in frames:\n",
    "        frame_array = image.img_to_array(frame)\n",
    "        frame_array = np.expand_dims(frame_array, axis=0)\n",
    "        frame_array = tf.keras.applications.resnet50.preprocess_input(frame_array)\n",
    "        feat = model.predict(frame_array, verbose=0)\n",
    "        features.append(feat.flatten())\n",
    "    return np.mean(features, axis=0)\n",
    "\n",
    "total_start = time.time()\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if cap.isOpened():\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    video_length_sec = total_frames / fps if fps > 0 else 0\n",
    "    print(f\"Original video length: {video_length_sec:.2f} seconds, FPS: {fps}, Total frames: {total_frames}\")\n",
    "cap.release()\n",
    "t0 = time.time()\n",
    "frames = extract_frames(video_path)\n",
    "t1 = time.time()\n",
    "print(f\"Frame extraction took: {t1 - t0:.2f} seconds, {len(frames)} frames extracted\")\n",
    "\n",
    "t2 = time.time()\n",
    "features = extract_cnn_features(frames)\n",
    "t3 = time.time()\n",
    "print(f\"ResNet feature extraction took: {t3 - t2:.2f} seconds\")\n",
    "t4 = time.time()\n",
    "features = features.reshape(1, -1)  # reshape for SVM\n",
    "y_pred = svm_model.predict(features)\n",
    "t5 = time.time()\n",
    "print(f\"SVM prediction took: {t5 - t4:.4f} seconds\")\n",
    "print(\"Predicted label:\", y_pred[0])\n",
    "\n",
    "total_end = time.time()\n",
    "print(f\"Total processing time: {total_end - total_start:.2f} seconds\")\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-09-07T13:39:53.298915Z",
     "iopub.execute_input": "2025-09-07T13:39:53.299135Z",
     "iopub.status.idle": "2025-09-07T13:40:37.114646Z",
     "shell.execute_reply.started": "2025-09-07T13:39:53.299117Z",
     "shell.execute_reply": "2025-09-07T13:40:37.114002Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": "2025-09-07 13:39:58.300592: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1757252398.654870      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1757252398.760396      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nI0000 00:00:1757252415.391126      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1757252415.391823      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001B[1m94765736/94765736\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 0us/step\nOriginal video length: 18.13 seconds, FPS: 30.0, Total frames: 544\nFrame extraction took: 2.86 seconds, 100 frames extracted\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1757252425.207871      97 service.cc:148] XLA service 0x7807f80023a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1757252425.209458      97 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1757252425.209477      97 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1757252425.880700      97 cuda_dnn.cc:529] Loaded cuDNN version 90300\nI0000 00:00:1757252429.042686      97 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "ResNet feature extraction took: 14.71 seconds\nSVM prediction took: 0.0026 seconds\nPredicted label: 0\nTotal processing time: 17.75 seconds\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": "import time\nimport cv2\nimport numpy as np\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.preprocessing import image\nimport joblib\nimport tensorflow as tf\nfrom tensorflow.keras import mixed_precision\n\n# --- Enable mixed precision for faster GPU inference ---\nmixed_precision.set_global_policy('mixed_float16')\n\n# --- Paths ---\nvideo_path = \"/kaggle/input/real-time-anomaly-detection-in-cctv-surveillance/data/normal/Normal_Videos001_x264.mp4\"\nsvm_path = \"/kaggle/input/svmbasedmodel/pytorch/default/1/svm_model.pkl\"\n\n# --- Load models ---\nmodel = ResNet50(weights='imagenet', include_top=False, pooling='avg', input_shape=(224,224,3))\nsvm_model = joblib.load(svm_path)\n\n# --- Warm-up GPU ---\ndummy = np.zeros((1, 224, 224, 3), dtype=np.float16)\nmodel.predict(dummy)\n\n# --- Functions ---\ndef extract_frames_fps(video_path, target_fps=5):\n    cap = cv2.VideoCapture(video_path)\n    if not cap.isOpened():\n        print(f\"Failed to open video: {video_path}\")\n        return []\n    \n    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    video_fps = cap.get(cv2.CAP_PROP_FPS)\n    total_seconds = int(total_frames / video_fps)\n    step = int(video_fps / target_fps)\n    \n    frames = []\n    for sec in range(total_seconds):\n        for i in range(0, int(video_fps), step):\n            frame_idx = sec * int(video_fps) + i\n            if frame_idx >= total_frames:\n                break\n            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n            ret, frame = cap.read()\n            if ret:\n                frames.append(cv2.resize(frame, (224, 224)))\n    cap.release()\n    return frames\n\ndef extract_cnn_features_batch(frames):\n    batch = np.array([tf.keras.applications.resnet50.preprocess_input(image.img_to_array(f)) for f in frames], dtype=np.float16)\n    feats = model.predict(batch, verbose=0)\n    return np.mean(feats, axis=0)\n\n# --- Timing starts ---\ntotal_start = time.time()\n\n# Video info\ncap = cv2.VideoCapture(video_path)\nif cap.isOpened():\n    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    fps = cap.get(cv2.CAP_PROP_FPS)\n    video_length_sec = total_frames / fps if fps > 0 else 0\n    print(f\"Original video length: {video_length_sec:.2f} seconds, FPS: {fps}, Total frames: {total_frames}\")\ncap.release()\n\nt0 = time.time()\nframes = extract_frames_fps(video_path, target_fps=5)\nt1 = time.time()\nprint(f\"Frame extraction took: {t1 - t0:.2f} seconds, {len(frames)} frames extracted\")\nt2 = time.time()\nfeatures = extract_cnn_features_batch(frames)\nt3 = time.time()\nprint(f\"ResNet50 batch feature extraction took: {t3 - t2:.2f} seconds\")\nt4 = time.time()\nfeatures = features.reshape(1, -1)\ny_pred = svm_model.predict(features)\nt5 = time.time()\nprint(f\"SVM prediction took: {t5 - t4:.4f} seconds\")\nprint(\"Predicted label:\", y_pred[0])\n\ntotal_end = time.time()\nprint(f\"Total processing time: {total_end - total_start:.2f} seconds\")\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-09-07T13:54:57.255831Z",
     "iopub.execute_input": "2025-09-07T13:54:57.256492Z",
     "iopub.status.idle": "2025-09-07T13:55:11.791940Z",
     "shell.execute_reply.started": "2025-09-07T13:54:57.256468Z",
     "shell.execute_reply": "2025-09-07T13:55:11.790985Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 5s/step\nOriginal video length: 18.13 seconds, FPS: 30.0, Total frames: 544\nFrame extraction took: 2.50 seconds, 90 frames extracted\nResNet50 batch feature extraction took: 6.28 seconds\nSVM prediction took: 0.0025 seconds\nPredicted label: 0\nTotal processing time: 8.79 seconds\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": "import time\nimport cv2\nimport numpy as np\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.preprocessing import image\nimport joblib\nimport tensorflow as tf\nfrom tensorflow.keras import mixed_precision\nfrom collections import deque\n\n# --- Mixed precision ---\nmixed_precision.set_global_policy('mixed_float16')\n\n# --- Paths ---\nvideo_path = \"/kaggle/input/real-time-anomaly-detection-in-cctv-surveillance/data/fighting/Fighting002_x264.mp4\"\nsvm_path = \"/kaggle/input/svmbasedmodel/pytorch/default/1/svm_model.pkl\"\n\n# --- Load models ---\nmodel = ResNet50(weights='imagenet', include_top=False, pooling='avg', input_shape=(224,224,3))\nsvm_model = joblib.load(svm_path)\n\n# --- Warm-up GPU ---\ndummy = np.zeros((1, 224, 224, 3), dtype=np.float16)\nmodel.predict(dummy)\n\n# --- Functions ---\ndef process_batch(frames, frame_indices):\n    \"\"\"Run ResNet + SVM on a batch of frames.\"\"\"\n    if not frames:\n        return\n    batch = np.array([tf.keras.applications.resnet50.preprocess_input(image.img_to_array(f)) for f in frames], dtype=np.float16)\n    feats = model.predict(batch, verbose=0)\n    preds = svm_model.predict(feats)\n    for idx, pred in zip(frame_indices, preds):\n        print(f\"Frame {idx}: Pred={pred}\")\n\n# --- Pipeline ---\ntarget_fps = 5   # only capture 5 frames per second\nbatch_size = 100\nqueue = deque()\nqueue_indices = []\n\ncap = cv2.VideoCapture(video_path)\ntotal_start = time.time()\ntotal_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\nvideo_fps = cap.get(cv2.CAP_PROP_FPS)\nprint(f\"Original video length: {total_frames/video_fps:.2f}s, FPS: {video_fps}, Total frames: {total_frames}\")\n\nframe_idx = 0\nstep = int(video_fps / target_fps)  # number of frames to skip to achieve target_fps\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # only process frames according to step\n    if frame_idx % step == 0:\n        frame_resized = cv2.resize(frame, (224, 224))\n        queue.append(frame_resized)\n        queue_indices.append(frame_idx)\n\n        # Process batch when queue is full\n        if len(queue) == batch_size:\n            batch_start = time.time()\n            process_batch(list(queue), list(queue_indices))\n            batch_end = time.time()\n            print(f\"Processed batch of {batch_size} frames in {batch_end - batch_start:.2f}s\")\n            queue.clear()\n            queue_indices.clear()\n\n    frame_idx += 1\n\n# Process any remaining frames\nif queue:\n    batch_start = time.time()\n    process_batch(list(queue), list(queue_indices))\n    batch_end = time.time()\n    print(f\"Processed final batch of {len(queue)} frames in {batch_end - batch_start:.2f}s\")\n\ncap.release()\ntotal_end = time.time()\nprint(f\"Total processing time for video: {total_end - total_start:.2f}s\")\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-09-07T14:26:49.051964Z",
     "iopub.execute_input": "2025-09-07T14:26:49.052221Z",
     "iopub.status.idle": "2025-09-07T14:27:07.805691Z",
     "shell.execute_reply.started": "2025-09-07T14:26:49.052205Z",
     "shell.execute_reply": "2025-09-07T14:27:07.804897Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 5s/step\nOriginal video length: 89.60s, FPS: 30.0, Total frames: 2688\nFrame 0: Pred=1\nFrame 6: Pred=1\nFrame 12: Pred=1\nFrame 18: Pred=1\nFrame 24: Pred=1\nFrame 30: Pred=1\nFrame 36: Pred=1\nFrame 42: Pred=1\nFrame 48: Pred=1\nFrame 54: Pred=1\nFrame 60: Pred=1\nFrame 66: Pred=1\nFrame 72: Pred=1\nFrame 78: Pred=1\nFrame 84: Pred=1\nFrame 90: Pred=1\nFrame 96: Pred=1\nFrame 102: Pred=1\nFrame 108: Pred=1\nFrame 114: Pred=1\nFrame 120: Pred=1\nFrame 126: Pred=1\nFrame 132: Pred=1\nFrame 138: Pred=1\nFrame 144: Pred=1\nFrame 150: Pred=1\nFrame 156: Pred=1\nFrame 162: Pred=1\nFrame 168: Pred=1\nFrame 174: Pred=1\nFrame 180: Pred=1\nFrame 186: Pred=1\nFrame 192: Pred=1\nFrame 198: Pred=1\nFrame 204: Pred=1\nFrame 210: Pred=1\nFrame 216: Pred=1\nFrame 222: Pred=1\nFrame 228: Pred=1\nFrame 234: Pred=1\nFrame 240: Pred=1\nFrame 246: Pred=1\nFrame 252: Pred=1\nFrame 258: Pred=1\nFrame 264: Pred=1\nFrame 270: Pred=1\nFrame 276: Pred=1\nFrame 282: Pred=1\nFrame 288: Pred=1\nFrame 294: Pred=1\nFrame 300: Pred=1\nFrame 306: Pred=1\nFrame 312: Pred=1\nFrame 318: Pred=1\nFrame 324: Pred=1\nFrame 330: Pred=1\nFrame 336: Pred=1\nFrame 342: Pred=1\nFrame 348: Pred=1\nFrame 354: Pred=1\nFrame 360: Pred=1\nFrame 366: Pred=1\nFrame 372: Pred=1\nFrame 378: Pred=1\nFrame 384: Pred=1\nFrame 390: Pred=1\nFrame 396: Pred=1\nFrame 402: Pred=1\nFrame 408: Pred=1\nFrame 414: Pred=1\nFrame 420: Pred=1\nFrame 426: Pred=1\nFrame 432: Pred=1\nFrame 438: Pred=1\nFrame 444: Pred=1\nFrame 450: Pred=1\nFrame 456: Pred=1\nFrame 462: Pred=1\nFrame 468: Pred=1\nFrame 474: Pred=1\nFrame 480: Pred=1\nFrame 486: Pred=1\nFrame 492: Pred=1\nFrame 498: Pred=1\nFrame 504: Pred=1\nFrame 510: Pred=1\nFrame 516: Pred=1\nFrame 522: Pred=1\nFrame 528: Pred=1\nFrame 534: Pred=1\nFrame 540: Pred=1\nFrame 546: Pred=1\nFrame 552: Pred=1\nFrame 558: Pred=1\nFrame 564: Pred=1\nFrame 570: Pred=1\nFrame 576: Pred=1\nFrame 582: Pred=1\nFrame 588: Pred=1\nFrame 594: Pred=1\nProcessed batch of 100 frames in 6.26s\nFrame 600: Pred=1\nFrame 606: Pred=1\nFrame 612: Pred=1\nFrame 618: Pred=1\nFrame 624: Pred=1\nFrame 630: Pred=1\nFrame 636: Pred=1\nFrame 642: Pred=1\nFrame 648: Pred=1\nFrame 654: Pred=1\nFrame 660: Pred=1\nFrame 666: Pred=1\nFrame 672: Pred=1\nFrame 678: Pred=1\nFrame 684: Pred=1\nFrame 690: Pred=1\nFrame 696: Pred=1\nFrame 702: Pred=1\nFrame 708: Pred=1\nFrame 714: Pred=1\nFrame 720: Pred=1\nFrame 726: Pred=1\nFrame 732: Pred=1\nFrame 738: Pred=1\nFrame 744: Pred=1\nFrame 750: Pred=1\nFrame 756: Pred=1\nFrame 762: Pred=1\nFrame 768: Pred=1\nFrame 774: Pred=1\nFrame 780: Pred=1\nFrame 786: Pred=1\nFrame 792: Pred=1\nFrame 798: Pred=1\nFrame 804: Pred=1\nFrame 810: Pred=1\nFrame 816: Pred=1\nFrame 822: Pred=1\nFrame 828: Pred=1\nFrame 834: Pred=1\nFrame 840: Pred=1\nFrame 846: Pred=1\nFrame 852: Pred=1\nFrame 858: Pred=1\nFrame 864: Pred=1\nFrame 870: Pred=1\nFrame 876: Pred=1\nFrame 882: Pred=1\nFrame 888: Pred=1\nFrame 894: Pred=1\nFrame 900: Pred=1\nFrame 906: Pred=1\nFrame 912: Pred=1\nFrame 918: Pred=1\nFrame 924: Pred=1\nFrame 930: Pred=1\nFrame 936: Pred=1\nFrame 942: Pred=1\nFrame 948: Pred=1\nFrame 954: Pred=1\nFrame 960: Pred=1\nFrame 966: Pred=1\nFrame 972: Pred=1\nFrame 978: Pred=1\nFrame 984: Pred=1\nFrame 990: Pred=1\nFrame 996: Pred=1\nFrame 1002: Pred=1\nFrame 1008: Pred=1\nFrame 1014: Pred=1\nFrame 1020: Pred=1\nFrame 1026: Pred=1\nFrame 1032: Pred=1\nFrame 1038: Pred=1\nFrame 1044: Pred=1\nFrame 1050: Pred=1\nFrame 1056: Pred=1\nFrame 1062: Pred=1\nFrame 1068: Pred=1\nFrame 1074: Pred=1\nFrame 1080: Pred=1\nFrame 1086: Pred=1\nFrame 1092: Pred=1\nFrame 1098: Pred=1\nFrame 1104: Pred=1\nFrame 1110: Pred=1\nFrame 1116: Pred=1\nFrame 1122: Pred=1\nFrame 1128: Pred=1\nFrame 1134: Pred=1\nFrame 1140: Pred=1\nFrame 1146: Pred=1\nFrame 1152: Pred=1\nFrame 1158: Pred=1\nFrame 1164: Pred=1\nFrame 1170: Pred=1\nFrame 1176: Pred=1\nFrame 1182: Pred=1\nFrame 1188: Pred=1\nFrame 1194: Pred=1\nProcessed batch of 100 frames in 0.69s\nFrame 1200: Pred=1\nFrame 1206: Pred=1\nFrame 1212: Pred=1\nFrame 1218: Pred=1\nFrame 1224: Pred=1\nFrame 1230: Pred=1\nFrame 1236: Pred=1\nFrame 1242: Pred=1\nFrame 1248: Pred=1\nFrame 1254: Pred=1\nFrame 1260: Pred=1\nFrame 1266: Pred=1\nFrame 1272: Pred=1\nFrame 1278: Pred=1\nFrame 1284: Pred=1\nFrame 1290: Pred=1\nFrame 1296: Pred=1\nFrame 1302: Pred=1\nFrame 1308: Pred=1\nFrame 1314: Pred=1\nFrame 1320: Pred=1\nFrame 1326: Pred=1\nFrame 1332: Pred=1\nFrame 1338: Pred=1\nFrame 1344: Pred=1\nFrame 1350: Pred=1\nFrame 1356: Pred=1\nFrame 1362: Pred=1\nFrame 1368: Pred=1\nFrame 1374: Pred=1\nFrame 1380: Pred=1\nFrame 1386: Pred=1\nFrame 1392: Pred=1\nFrame 1398: Pred=1\nFrame 1404: Pred=1\nFrame 1410: Pred=1\nFrame 1416: Pred=1\nFrame 1422: Pred=1\nFrame 1428: Pred=1\nFrame 1434: Pred=1\nFrame 1440: Pred=1\nFrame 1446: Pred=1\nFrame 1452: Pred=1\nFrame 1458: Pred=1\nFrame 1464: Pred=1\nFrame 1470: Pred=1\nFrame 1476: Pred=1\nFrame 1482: Pred=1\nFrame 1488: Pred=1\nFrame 1494: Pred=1\nFrame 1500: Pred=1\nFrame 1506: Pred=1\nFrame 1512: Pred=1\nFrame 1518: Pred=1\nFrame 1524: Pred=1\nFrame 1530: Pred=1\nFrame 1536: Pred=1\nFrame 1542: Pred=1\nFrame 1548: Pred=1\nFrame 1554: Pred=1\nFrame 1560: Pred=1\nFrame 1566: Pred=1\nFrame 1572: Pred=1\nFrame 1578: Pred=1\nFrame 1584: Pred=1\nFrame 1590: Pred=1\nFrame 1596: Pred=1\nFrame 1602: Pred=1\nFrame 1608: Pred=1\nFrame 1614: Pred=1\nFrame 1620: Pred=1\nFrame 1626: Pred=1\nFrame 1632: Pred=1\nFrame 1638: Pred=1\nFrame 1644: Pred=1\nFrame 1650: Pred=1\nFrame 1656: Pred=1\nFrame 1662: Pred=1\nFrame 1668: Pred=1\nFrame 1674: Pred=1\nFrame 1680: Pred=1\nFrame 1686: Pred=1\nFrame 1692: Pred=1\nFrame 1698: Pred=1\nFrame 1704: Pred=1\nFrame 1710: Pred=1\nFrame 1716: Pred=1\nFrame 1722: Pred=1\nFrame 1728: Pred=1\nFrame 1734: Pred=1\nFrame 1740: Pred=1\nFrame 1746: Pred=1\nFrame 1752: Pred=1\nFrame 1758: Pred=1\nFrame 1764: Pred=1\nFrame 1770: Pred=1\nFrame 1776: Pred=1\nFrame 1782: Pred=1\nFrame 1788: Pred=1\nFrame 1794: Pred=1\nProcessed batch of 100 frames in 0.69s\nFrame 1800: Pred=1\nFrame 1806: Pred=1\nFrame 1812: Pred=1\nFrame 1818: Pred=1\nFrame 1824: Pred=1\nFrame 1830: Pred=1\nFrame 1836: Pred=1\nFrame 1842: Pred=1\nFrame 1848: Pred=1\nFrame 1854: Pred=1\nFrame 1860: Pred=1\nFrame 1866: Pred=1\nFrame 1872: Pred=1\nFrame 1878: Pred=1\nFrame 1884: Pred=1\nFrame 1890: Pred=1\nFrame 1896: Pred=1\nFrame 1902: Pred=1\nFrame 1908: Pred=1\nFrame 1914: Pred=1\nFrame 1920: Pred=1\nFrame 1926: Pred=1\nFrame 1932: Pred=1\nFrame 1938: Pred=1\nFrame 1944: Pred=1\nFrame 1950: Pred=1\nFrame 1956: Pred=1\nFrame 1962: Pred=1\nFrame 1968: Pred=1\nFrame 1974: Pred=1\nFrame 1980: Pred=1\nFrame 1986: Pred=1\nFrame 1992: Pred=1\nFrame 1998: Pred=1\nFrame 2004: Pred=1\nFrame 2010: Pred=1\nFrame 2016: Pred=1\nFrame 2022: Pred=1\nFrame 2028: Pred=1\nFrame 2034: Pred=1\nFrame 2040: Pred=1\nFrame 2046: Pred=1\nFrame 2052: Pred=1\nFrame 2058: Pred=1\nFrame 2064: Pred=1\nFrame 2070: Pred=1\nFrame 2076: Pred=1\nFrame 2082: Pred=1\nFrame 2088: Pred=1\nFrame 2094: Pred=1\nFrame 2100: Pred=1\nFrame 2106: Pred=1\nFrame 2112: Pred=1\nFrame 2118: Pred=1\nFrame 2124: Pred=1\nFrame 2130: Pred=1\nFrame 2136: Pred=1\nFrame 2142: Pred=1\nFrame 2148: Pred=1\nFrame 2154: Pred=1\nFrame 2160: Pred=1\nFrame 2166: Pred=1\nFrame 2172: Pred=1\nFrame 2178: Pred=1\nFrame 2184: Pred=1\nFrame 2190: Pred=1\nFrame 2196: Pred=1\nFrame 2202: Pred=1\nFrame 2208: Pred=1\nFrame 2214: Pred=1\nFrame 2220: Pred=1\nFrame 2226: Pred=1\nFrame 2232: Pred=1\nFrame 2238: Pred=1\nFrame 2244: Pred=1\nFrame 2250: Pred=1\nFrame 2256: Pred=1\nFrame 2262: Pred=1\nFrame 2268: Pred=1\nFrame 2274: Pred=1\nFrame 2280: Pred=1\nFrame 2286: Pred=1\nFrame 2292: Pred=1\nFrame 2298: Pred=1\nFrame 2304: Pred=1\nFrame 2310: Pred=1\nFrame 2316: Pred=1\nFrame 2322: Pred=1\nFrame 2328: Pred=1\nFrame 2334: Pred=1\nFrame 2340: Pred=1\nFrame 2346: Pred=1\nFrame 2352: Pred=1\nFrame 2358: Pred=1\nFrame 2364: Pred=1\nFrame 2370: Pred=1\nFrame 2376: Pred=1\nFrame 2382: Pred=1\nFrame 2388: Pred=1\nFrame 2394: Pred=1\nProcessed batch of 100 frames in 0.69s\nFrame 2400: Pred=1\nFrame 2406: Pred=1\nFrame 2412: Pred=1\nFrame 2418: Pred=1\nFrame 2424: Pred=1\nFrame 2430: Pred=1\nFrame 2436: Pred=1\nFrame 2442: Pred=1\nFrame 2448: Pred=1\nFrame 2454: Pred=1\nFrame 2460: Pred=1\nFrame 2466: Pred=1\nFrame 2472: Pred=1\nFrame 2478: Pred=1\nFrame 2484: Pred=1\nFrame 2490: Pred=1\nFrame 2496: Pred=1\nFrame 2502: Pred=1\nFrame 2508: Pred=1\nFrame 2514: Pred=1\nFrame 2520: Pred=1\nFrame 2526: Pred=1\nFrame 2532: Pred=1\nFrame 2538: Pred=1\nFrame 2544: Pred=1\nFrame 2550: Pred=1\nFrame 2556: Pred=1\nFrame 2562: Pred=1\nFrame 2568: Pred=1\nFrame 2574: Pred=1\nFrame 2580: Pred=1\nFrame 2586: Pred=1\nFrame 2592: Pred=1\nFrame 2598: Pred=1\nFrame 2604: Pred=1\nFrame 2610: Pred=1\nFrame 2616: Pred=1\nFrame 2622: Pred=1\nFrame 2628: Pred=1\nFrame 2634: Pred=1\nFrame 2640: Pred=1\nFrame 2646: Pred=1\nFrame 2652: Pred=1\nFrame 2658: Pred=1\nFrame 2664: Pred=1\nFrame 2670: Pred=1\nFrame 2676: Pred=1\nFrame 2682: Pred=1\nProcessed final batch of 48 frames in 4.09s\nTotal processing time for video: 12.97s\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": "import os\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing import image\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report, accuracy_score\n\ndata_dir = '/kaggle/input/real-time-anomaly-detection-in-cctv-surveillance/'\nvideo_dir = os.path.join(data_dir, 'data')\ntrain_csv = os.path.join(video_dir, 'train.csv')\ntest_csv = os.path.join(video_dir, 'test.csv')\n\nbackbone_name = \"mobilenetv2\" \nnum_frames = 5\nthreat_classes = ['abuse', 'arrest', 'arson', 'assault', 'burglary', 'explosion', \n                  'fighting', 'roadaccidents', 'robbery', 'shooting', 'shoplifting', \n                  'stealing', 'vandalism']\nnormal_class = ['normal']\n\ndef load_backbone(name):\n    if name.lower() == \"resnet50\":\n        from tensorflow.keras.applications import ResNet50\n        from tensorflow.keras.applications.resnet50 import preprocess_input\n        model = ResNet50(weights=\"imagenet\", include_top=False, pooling=\"avg\")\n    elif name.lower() == \"mobilenetv2\":\n        from tensorflow.keras.applications import MobileNetV2\n        from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n        model = MobileNetV2(weights=\"imagenet\", include_top=False, pooling=\"avg\")\n    elif name.lower() == \"efficientnetb0\":\n        from tensorflow.keras.applications import EfficientNetB0\n        from tensorflow.keras.applications.efficientnet import preprocess_input\n        model = EfficientNetB0(weights=\"imagenet\", include_top=False, pooling=\"avg\")\n    else:\n        raise ValueError(\"Unknown backbone\")\n    return model, preprocess_input\n\ndef extract_frames(video_path, num_frames=num_frames):\n    cap = cv2.VideoCapture(video_path)\n    if not cap.isOpened():\n        print(f\"Failed to open video: {video_path}\")\n        return []\n    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    step = max(1, total_frames // num_frames)\n    frames = []\n    for i in range(0, total_frames, step):\n        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n        ret, frame = cap.read()\n        if ret:\n            frames.append(cv2.resize(frame, (224, 224)))\n        if len(frames) >= num_frames:\n            break\n    cap.release()\n    return frames\n\ndef extract_cnn_features(frames, model, preprocess_input):\n    if not frames:\n        return None\n    features = []\n    for frame in frames:\n        frame_array = image.img_to_array(frame)\n        frame_array = np.expand_dims(frame_array, axis=0)\n        frame_array = preprocess_input(frame_array)\n        feat = model.predict(frame_array, verbose=0)\n        features.append(feat.flatten())\n    return np.mean(features, axis=0)\n\ndef load_dataset(csv_path, model, preprocess_input):\n    df = pd.read_csv(csv_path)\n    X, y = [], []\n    for _, row in df.iterrows():\n        relative_path = row['video_name'].replace('\\n', '').replace('\\\\', '/')\n        video_path = os.path.join(data_dir, relative_path)\n        label = 1 if row['label'] in threat_classes else (0 if row['label'] in normal_class else -1)\n        if label == -1:\n            continue\n        frames = extract_frames(video_path, num_frames=num_frames)\n        if frames:\n            features = extract_cnn_features(frames, model, preprocess_input)\n            if features is not None:\n                X.append(features)\n                y.append(label)\n    return np.array(X), np.array(y)\n\n\nprint(f\"Using backbone: {backbone_name}\")\nmodel, preprocess_input = load_backbone(backbone_name)\n\n# Train set\nX_train, y_train = load_dataset(train_csv, model, preprocess_input)\nprint(f\"Train shape: {X_train.shape}, Labels: {y_train.shape}\")\n\n# Train SVM\nsvm_model = SVC(kernel=\"rbf\", C=1.0, gamma=\"scale\")\nsvm_model.fit(X_train, y_train)\n\n# Test set\nX_test, y_test = load_dataset(test_csv, model, preprocess_input)\nprint(f\"Test shape: {X_test.shape}, Labels: {y_test.shape}\")\n\n# Evaluate\ny_pred = svm_model.predict(X_test)\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred, digits=4))\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-09-07T16:54:30.683253Z",
     "iopub.execute_input": "2025-09-07T16:54:30.683789Z",
     "iopub.status.idle": "2025-09-07T17:13:21.049538Z",
     "shell.execute_reply.started": "2025-09-07T16:54:30.683764Z",
     "shell.execute_reply": "2025-09-07T17:13:21.048832Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "🔎 Using backbone: mobilenetv2\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "/tmp/ipykernel_36/2323677778.py:39: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n  model = MobileNetV2(weights=\"imagenet\", include_top=False, pooling=\"avg\")\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1757264073.927747     100 service.cc:148] XLA service 0x794480002500 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1757264073.929418     100 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1757264073.929443     100 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1757264074.492899     100 cuda_dnn.cc:529] Loaded cuDNN version 90300\nI0000 00:00:1757264078.062333     100 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Train shape: (1520, 1280), Labels: (1520,)\nTest shape: (380, 1280), Labels: (380,)\nClassification Report:\n               precision    recall  f1-score   support\n\n           0     0.8528    0.8842    0.8682       190\n           1     0.8798    0.8474    0.8633       190\n\n    accuracy                         0.8658       380\n   macro avg     0.8663    0.8658    0.8657       380\nweighted avg     0.8663    0.8658    0.8657       380\n\nAccuracy: 0.8657894736842106\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": "import joblib\n\njoblib.dump(svm_model, \"svm_efficientnet_model.pkl\")\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-09-07T17:13:57.477187Z",
     "iopub.execute_input": "2025-09-07T17:13:57.477914Z",
     "iopub.status.idle": "2025-09-07T17:13:57.494765Z",
     "shell.execute_reply.started": "2025-09-07T17:13:57.477876Z",
     "shell.execute_reply": "2025-09-07T17:13:57.493959Z"
    }
   },
   "outputs": [
    {
     "execution_count": 6,
     "output_type": "execute_result",
     "data": {
      "text/plain": "['svm_efficientnet_model.pkl']"
     },
     "metadata": {}
    }
   ],
   "execution_count": 6
  }
 ]
}
